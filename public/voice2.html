<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sommalier Gent - Voice Agent</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        body {
            overflow: hidden;
        }

        .voice2-container {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            z-index: 1000;
        }

        .voice2-content {
            width: 90%;
            max-width: 800px;
            height: 90vh;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            border-radius: 20px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
            padding: 40px;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            border: 1px solid rgba(255, 255, 255, 0.2);
            position: relative;
        }

        .voice-button-large {
            width: 200px;
            height: 200px;
            border-radius: 50%;
            border: 4px solid rgba(255, 255, 255, 0.3);
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 64px;
            color: white;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
            position: relative;
            z-index: 10001;
            pointer-events: auto !important;
        }

        .voice-button-large:hover {
            background: rgba(255, 255, 255, 0.25);
            transform: scale(1.05);
            border-color: rgba(255, 255, 255, 0.5);
        }

        .voice-button-large.listening {
            background: rgba(255, 0, 0, 0.4);
            border-color: rgba(255, 0, 0, 0.6);
            animation: pulse 1.5s infinite;
        }

        .voice-button-large.speaking {
            background: rgba(0, 255, 0, 0.4);
            border-color: rgba(0, 255, 0, 0.6);
            animation: pulse 1.5s infinite;
        }

        .voice-button-large.processing {
            background: rgba(255, 165, 0, 0.4);
            border-color: rgba(255, 165, 0, 0.6);
        }

        @keyframes pulse {
            0%, 100% { 
                transform: scale(1);
                box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
            }
            50% { 
                transform: scale(1.1);
                box-shadow: 0 12px 48px rgba(0, 0, 0, 0.4);
            }
        }

        .status-text {
            color: white;
            font-size: 20px;
            text-align: center;
            margin-top: 30px;
            min-height: 30px;
            font-weight: 300;
        }

        .conversation-transcript {
            position: absolute;
            top: 20px;
            left: 20px;
            right: 20px;
            bottom: 200px;
            overflow-y: auto;
            padding: 20px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 15px;
            display: none;
        }

        .conversation-transcript.show {
            display: block;
        }

        .transcript-message {
            margin-bottom: 15px;
            padding: 12px 18px;
            border-radius: 12px;
            max-width: 80%;
            word-wrap: break-word;
        }

        .transcript-message.user {
            background: rgba(255, 255, 255, 0.2);
            margin-left: auto;
            text-align: right;
        }

        .transcript-message.assistant {
            background: rgba(255, 255, 255, 0.1);
            margin-right: auto;
        }

        .toggle-transcript {
            position: absolute;
            top: 20px;
            right: 20px;
            padding: 10px 20px;
            background: rgba(255, 255, 255, 0.2);
            border: 1px solid rgba(255, 255, 255, 0.3);
            border-radius: 20px;
            color: white;
            cursor: pointer;
            font-size: 14px;
            z-index: 10002;
            pointer-events: auto !important;
        }

        /* Hide agent but keep it functional */
        #embedded-messaging-agent {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 1;
            opacity: 0;
            pointer-events: none !important;
        }

        #embedded-messaging-agent * {
            pointer-events: none !important;
        }

        #embedded-messaging-agent iframe {
            width: 100% !important;
            height: 100% !important;
            pointer-events: none !important;
        }

        .embeddedServiceSidebar {
            pointer-events: none !important;
        }

        .embeddedServiceSidebar * {
            pointer-events: none !important;
        }
    </style>
</head>
<body>
    <div class="background-container">
        <img src="background.png" alt="Background" class="background-image">
    </div>
    
    <div class="voice2-container">
        <div class="voice2-content">
            <!-- Hidden Salesforce Agentforce Agent -->
            <div id="embedded-messaging-agent"></div>
            
            <button class="toggle-transcript" onclick="toggleTranscript()">Toggle Transcript</button>
            
            <div class="conversation-transcript" id="transcript"></div>
            
            <button class="voice-button-large" id="voiceButton" onclick="toggleVoice()">
                üé§
            </button>
            <div class="status-text" id="statusText">Click to start speaking</div>
        </div>
    </div>

    <!-- Agentforce Bootstrap Script -->
    <script type='text/javascript'>
    var targetContainer = document.getElementById('embedded-messaging-agent');
    var agentReady = false;
    var lastMessageText = '';
    
    function initEmbeddedMessaging() {
        try {
            if (targetContainer && window.embeddedservice_bootstrap) {
                embeddedservice_bootstrap.settings.targetElement = targetContainer;
            }
            
            embeddedservice_bootstrap.settings.language = 'en_US';
            embeddedservice_bootstrap.settings.widgetFontSize = "40px";
            
            embeddedservice_bootstrap.init(
                '00DHu00000izUN6',
                'SommalierGent_1',
                'https://storm-11c5bf736713cf.my.site.com/ESWSommalierGent1762152842517',
                {
                    scrt2URL: 'https://storm-11c5bf736713cf.my.salesforce-scrt.com'
                }
            );
        } catch (err) {
            console.error('Error loading Embedded Messaging: ', err);
        }
    }
    
    window.addEventListener("onEmbeddedMessagingReady", function() {
        if (targetContainer && window.embeddedservice_bootstrap) {
            embeddedservice_bootstrap.settings.targetElement = targetContainer;
            embeddedservice_bootstrap.settings.widgetFontSize = "40px";
            
            setTimeout(function() {
                if (embeddedservice_bootstrap.utilAPI && embeddedservice_bootstrap.utilAPI.launchChat) {
                    embeddedservice_bootstrap.utilAPI.launchChat();
                    agentReady = true;
                    document.getElementById('statusText').textContent = 'Ready - Click to speak';
                }
            }, 1000);
        }
    });

    var widgetChecker = setInterval(function() {
        var sidebar = document.querySelector('.embeddedServiceSidebar');
        
        if (sidebar && targetContainer) {
            if (!targetContainer.contains(sidebar)) {
                try {
                    sidebar.remove();
                    targetContainer.appendChild(sidebar);
                    agentReady = true;
                } catch (err) {
                    console.error('Error moving sidebar:', err);
                }
            }
        }
        
        if (sidebar && targetContainer.contains(sidebar)) {
            clearInterval(widgetChecker);
            agentReady = true;
            document.getElementById('statusText').textContent = 'Ready - Click to speak';
        }
    }, 200);
    
    setTimeout(function() {
        clearInterval(widgetChecker);
    }, 10000);
    </script>
    <script type='text/javascript' src='https://storm-11c5bf736713cf.my.site.com/ESWSommalierGent1762152842517/assets/js/bootstrap.min.js' onload='initEmbeddedMessaging()'></script>

    <script>
        let isListening = false;
        let isProcessing = false;
        let mediaRecorder = null;
        let audioChunks = [];
        let recognition = null;

        function toggleVoice() {
            if (!agentReady) {
                document.getElementById('statusText').textContent = 'Agent initializing... Please wait';
                return;
            }

            if (isProcessing) {
                return;
            }

            if (isListening) {
                stopListening();
            } else {
                startListening();
            }
        }

        function startListening() {
            // Try Web Speech API first (simpler)
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'en-US';

                recognition.onstart = () => {
                    isListening = true;
                    updateUI('listening');
                    document.getElementById('statusText').textContent = 'Listening...';
                };

                recognition.onresult = (event) => {
                    const transcript = event.results[0][0].transcript;
                    addToTranscript('user', transcript);
                    sendToAgentforce(transcript);
                };

                recognition.onerror = (event) => {
                    console.error('Speech recognition error:', event.error);
                    updateUI('idle');
                    document.getElementById('statusText').textContent = 'Error: ' + event.error;
                    isListening = false;
                };

                recognition.onend = () => {
                    isListening = false;
                    if (!isProcessing) {
                        updateUI('idle');
                    }
                };

                recognition.start();
            } else {
                // Fallback to media recording + OpenAI transcription
                startMediaRecording();
            }
        }

        function stopListening() {
            if (recognition) {
                recognition.stop();
            }
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
            isListening = false;
            updateUI('idle');
            document.getElementById('statusText').textContent = 'Stopped';
        }

        async function startMediaRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    const base64Audio = await blobToBase64(audioBlob);
                    
                    // Send to OpenAI for transcription
                    try {
                        const response = await fetch('/api/transcribe', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({ audio: base64Audio })
                        });
                        
                        const data = await response.json();
                        if (data.text) {
                            addToTranscript('user', data.text);
                            sendToAgentforce(data.text);
                        }
                    } catch (err) {
                        console.error('Transcription error:', err);
                    }
                    
                    stream.getTracks().forEach(track => track.stop());
                };

                isListening = true;
                updateUI('listening');
                document.getElementById('statusText').textContent = 'Listening...';
                mediaRecorder.start();
            } catch (err) {
                console.error('Error accessing microphone:', err);
                document.getElementById('statusText').textContent = 'Error accessing microphone';
            }
        }

        function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => resolve(reader.result.split(',')[1]);
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        }

        async function sendToAgentforce(userMessage) {
            isProcessing = true;
            updateUI('processing');
            document.getElementById('statusText').textContent = 'Processing...';

            try {
                const iframe = document.querySelector('#embedded-messaging-agent iframe, .embeddedServiceSidebar iframe');
                
                if (!iframe) {
                    throw new Error('Agent iframe not found');
                }

                // Wait for iframe to be ready
                await new Promise(resolve => setTimeout(resolve, 1000));

                try {
                    const iframeDoc = iframe.contentDocument || iframe.contentWindow.document;
                    const inputSelectors = [
                        'input[type="text"]',
                        'textarea',
                        '[contenteditable="true"]',
                        '[role="textbox"]'
                    ];
                    
                    let inputField = null;
                    for (const selector of inputSelectors) {
                        inputField = iframeDoc.querySelector(selector);
                        if (inputField) break;
                    }
                    
                    if (inputField) {
                        inputField.focus();
                        
                        if (inputField.tagName === 'INPUT' || inputField.tagName === 'TEXTAREA') {
                            inputField.value = userMessage;
                        } else {
                            inputField.textContent = userMessage;
                        }
                        
                        ['input', 'change'].forEach(eventType => {
                            const event = new Event(eventType, { bubbles: true });
                            inputField.dispatchEvent(event);
                        });
                        
                        setTimeout(() => {
                            const sendButton = iframeDoc.querySelector('button[type="submit"], button[aria-label*="Send"], [class*="send"]');
                            if (sendButton) {
                                sendButton.click();
                            } else {
                                const enterEvent = new KeyboardEvent('keydown', {
                                    key: 'Enter',
                                    code: 'Enter',
                                    keyCode: 13,
                                    bubbles: true
                                });
                                inputField.dispatchEvent(enterEvent);
                            }
                            
                            monitorAgentResponse();
                        }, 500);
                    } else {
                        throw new Error('Input field not found');
                    }
                } catch (err) {
                    console.error('Cross-origin error:', err);
                    // Try postMessage
                    iframe.contentWindow.postMessage({
                        type: 'sendMessage',
                        message: userMessage
                    }, '*');
                    monitorAgentResponse();
                }
            } catch (error) {
                console.error('Error:', error);
                document.getElementById('statusText').textContent = 'Error: ' + error.message;
                isProcessing = false;
                updateUI('idle');
            }
        }

        let responseObserver = null;

        function monitorAgentResponse() {
            const sidebar = document.querySelector('.embeddedServiceSidebar');
            let lastText = '';
            
            if (sidebar && !responseObserver) {
                responseObserver = new MutationObserver(() => {
                    const currentText = (sidebar.textContent || '').trim();
                    
                    if (currentText && currentText !== lastText && currentText.length > lastText.length + 20) {
                        const newText = currentText.substring(lastText.length).trim();
                        
                        if (newText.length > 20 && !newText.includes('Type your message')) {
                            lastText = currentText;
                            addToTranscript('assistant', newText);
                            speakWithOpenAI(newText);
                            isProcessing = false;
                            return;
                        }
                    }
                });
                
                responseObserver.observe(sidebar, {
                    childList: true,
                    subtree: true,
                    characterData: true
                });
            }

            // Also poll for changes
            const pollInterval = setInterval(() => {
                const iframe = document.querySelector('#embedded-messaging-agent iframe');
                if (iframe) {
                    try {
                        const iframeDoc = iframe.contentDocument || iframe.contentWindow.document;
                        const messages = iframeDoc.querySelectorAll('[class*="message"], [role="article"]');
                        
                        if (messages.length > 0) {
                            const lastMsg = messages[messages.length - 1];
                            const msgText = (lastMsg.textContent || '').trim();
                            
                            if (msgText && msgText.length > 20 && !msgText.includes('Type your message')) {
                                const isUser = lastMsg.classList.contains('user') || lastMsg.classList.contains('sent');
                                if (!isUser && msgText !== lastMessageText) {
                                    lastMessageText = msgText;
                                    clearInterval(pollInterval);
                                    if (responseObserver) {
                                        responseObserver.disconnect();
                                        responseObserver = null;
                                    }
                                    addToTranscript('assistant', msgText);
                                    speakWithOpenAI(msgText);
                                    isProcessing = false;
                                }
                            }
                        }
                    } catch (err) {
                        // Cross-origin
                    }
                }
            }, 1000);

            setTimeout(() => {
                clearInterval(pollInterval);
                if (isProcessing) {
                    document.getElementById('statusText').textContent = 'No response - try again';
                    isProcessing = false;
                    updateUI('idle');
                }
            }, 30000);
        }

        async function speakWithOpenAI(text) {
            updateUI('speaking');
            document.getElementById('statusText').textContent = 'Speaking...';

            try {
                const response = await fetch('/api/tts', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: text })
                });

                if (response.ok) {
                    const audioBlob = await response.blob();
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const audio = new Audio(audioUrl);
                    
                    audio.onended = () => {
                        updateUI('idle');
                        document.getElementById('statusText').textContent = 'Click to speak again';
                        URL.revokeObjectURL(audioUrl);
                    };
                    
                    audio.onerror = () => {
                        updateUI('idle');
                        document.getElementById('statusText').textContent = 'Error playing audio';
                    };
                    
                    audio.play();
                } else {
                    // Fallback to browser TTS
                    speakWithBrowserTTS(text);
                }
            } catch (error) {
                console.error('TTS error:', error);
                // Fallback to browser TTS
                speakWithBrowserTTS(text);
            }
        }

        function speakWithBrowserTTS(text) {
            if ('speechSynthesis' in window) {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = 'en-US';
                utterance.rate = 1.0;
                utterance.pitch = 1.0;
                utterance.volume = 1.0;

                utterance.onend = () => {
                    updateUI('idle');
                    document.getElementById('statusText').textContent = 'Click to speak again';
                };

                utterance.onerror = () => {
                    updateUI('idle');
                    document.getElementById('statusText').textContent = 'Error speaking';
                };

                window.speechSynthesis.speak(utterance);
            }
        }

        function updateUI(state) {
            const button = document.getElementById('voiceButton');
            button.className = 'voice-button-large';
            
            if (state === 'listening') {
                button.classList.add('listening');
                button.textContent = 'üî¥';
            } else if (state === 'speaking') {
                button.classList.add('speaking');
                button.textContent = 'üîä';
            } else if (state === 'processing') {
                button.classList.add('processing');
                button.textContent = '‚è≥';
            } else {
                button.textContent = 'üé§';
            }
        }

        function addToTranscript(role, text) {
            const transcript = document.getElementById('transcript');
            transcript.classList.add('show');
            
            const messageDiv = document.createElement('div');
            messageDiv.className = `transcript-message ${role}`;
            messageDiv.textContent = text;
            transcript.appendChild(messageDiv);
            transcript.scrollTop = transcript.scrollHeight;
        }

        function toggleTranscript() {
            const transcript = document.getElementById('transcript');
            transcript.classList.toggle('show');
        }
    </script>
</body>
</html>

